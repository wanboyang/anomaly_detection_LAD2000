---
layout: default
---

<!-- Language Switch Buttons -->
<div align="center">
  <a href="#english" class="btn btn-primary">English</a>
  <a href="#chinese" class="btn btn-secondary">ä¸­æ–‡</a>
</div>

<div id="english">

# LAD2000: A Large-scale Video Anomaly Detection Benchmark and Computational Model

[![Paper](https://img.shields.io/badge/Paper-ArXiv-red)](https://arxiv.org/abs/2106.08570)
[![License](https://img.shields.io/badge/License-MIT-blue)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.5%2B-green)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.2.0-orange)](https://pytorch.org/)

## Abstract

This repository presents **LAD2000**, a comprehensive video anomaly detection benchmark containing 2,000 videos across 14 distinct anomaly categories. We introduce a novel computational framework for video anomaly detection that leverages ConvLSTM-based architectures to simultaneously perform anomaly classification and temporal localization. Our approach demonstrates state-of-the-art performance on multiple benchmark datasets including LAD2000, Avenue, Ped2, ShanghaiTech, and UCF-Crime.

## ğŸ¯ Key Features

- **Large-scale Dataset**: 2,000 videos with 14 anomaly categories
- **Multi-modal Features**: Support for RGB, Flow, and combined I3D features
- **Dual-task Learning**: Simultaneous anomaly classification and temporal localization
- **Comprehensive Benchmarks**: Evaluation on 5 major video anomaly detection datasets
- **Reproducible Implementation**: Complete training and evaluation pipelines

## ğŸ“Š Dataset Overview

| Category | # Videos | Description |
|----------|----------|-------------|
| Crash | 143 | Vehicle collisions and accidents |
| Crowd | 156 | Abnormal crowd gatherings |
| Destroy | 142 | Property destruction |
| Drop | 145 | Objects falling from height |
| Falling | 148 | People falling down |
| FallIntoWater | 139 | Falling into water bodies |
| Fighting | 147 | Physical altercations |
| Fire | 144 | Fire incidents |
| Hurt | 146 | Physical injuries |
| Loitering | 142 | Suspicious lingering |
| Panic | 143 | Panic situations |
| Thiefing | 145 | Theft activities |
| Trampled | 141 | Crowd stampedes |
| Violence | 129 | Violent behaviors |

## ğŸ—ï¸ Model Architecture

Our proposed **AED (Anomaly Event Detection)** framework consists of:

1. **ConvLSTM Encoder**: Captures spatio-temporal dependencies
2. **Classification Head**: Predicts anomaly categories
3. **Regression Head**: Localizes temporal segments

### Model Variants:
- **AED**: Single-layer ConvLSTM
- **AED_T**: Two-layer ConvLSTM with enhanced temporal modeling

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/wanboyang/anomaly_detection_LAD2000.git
cd anomaly_detection_LAD2000

# Create environment
conda env create -f environment.yaml
conda activate anomaly_icme
```

### Data Preparation

1. Download LAD2000 dataset from [Baidu Netdisk](https://pan.baidu.com/s/1LmNAWnR-RPqo-azCgASvfg) (password: avt8)
2. Extract I3D features or use pre-extracted features
3. Update dataset paths in configuration

### Training

```bash
# Train on LAD2000 dataset
sh LAD2000T_i3d.sh

# Train on other datasets
sh ped2_i3d.sh      # UCSD Ped2
sh Avenue_i3d.sh    # Avenue
sh shanghaitech_i3d.sh  # ShanghaiTech
sh UCF_i3d.sh       # UCF-Crime
```

### Evaluation

```bash
python test.py --dataset_name LAD2000 --model_name AED_T --feature_modal combine
```

## ğŸ“ˆ Results

| Dataset | AUC | Frame-level AP | Video-level AP |
|---------|-----|----------------|----------------|
| LAD2000 | 87.2 | 85.6 | 89.1 |
| Avenue | 91.4 | 90.2 | 92.8 |
| Ped2 | 96.8 | 95.3 | 97.5 |
| ShanghaiTech | 84.7 | 82.9 | 86.3 |
| UCF-Crime | 83.5 | 81.2 | 85.1 |

## ğŸ“š Citation

If you find this work useful for your research, please cite:

```bibtex
@article{wan2021anomaly,
  title={Anomaly detection in video sequences: A benchmark and computational model},
  author={Wan, Boyang and Jiang, Wenhui and Fang, Yuming and Luo, Zhiyuan and Ding, Guanqun},
  journal={IET Image Processing},
  year={2021},
  publisher={Wiley Online Library}
}
```

## ğŸ¤ Acknowledgements

We thank the contributors of [W-TALC](https://github.com/sujoyp/wtalc-pytorch) and the PyTorch team for their excellent frameworks.

## ğŸ“§ Contact

For questions and suggestions, please contact:
- **Boyang Wan** - wanboyangjerry@163.com

</div>

<div id="chinese" style="display: none;">

# LAD2000: å¤§è§„æ¨¡è§†é¢‘å¼‚å¸¸æ£€æµ‹åŸºå‡†ä¸è®¡ç®—æ¨¡å‹

[![è®ºæ–‡](https://img.shields.io/badge/è®ºæ–‡-ArXiv-red)](https://arxiv.org/abs/2106.08570)
[![è®¸å¯è¯](https://img.shields.io/badge/è®¸å¯è¯-MIT-blue)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.5%2B-green)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.2.0-orange)](https://pytorch.org/)

## æ‘˜è¦

æœ¬ä»“åº“æå‡ºäº† **LAD2000**ï¼Œä¸€ä¸ªåŒ…å« 2,000 ä¸ªè§†é¢‘ã€æ¶µç›– 14 ç§ä¸åŒå¼‚å¸¸ç±»åˆ«çš„ç»¼åˆæ€§è§†é¢‘å¼‚å¸¸æ£€æµ‹åŸºå‡†ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„è§†é¢‘å¼‚å¸¸æ£€æµ‹è®¡ç®—æ¡†æ¶ï¼Œåˆ©ç”¨åŸºäº ConvLSTM çš„æ¶æ„åŒæ—¶æ‰§è¡Œå¼‚å¸¸åˆ†ç±»å’Œæ—¶é—´å®šä½ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨åŒ…æ‹¬ LAD2000ã€Avenueã€Ped2ã€ShanghaiTech å’Œ UCF-Crime åœ¨å†…çš„å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå±•ç¤ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ¯ ä¸»è¦ç‰¹æ€§

- **å¤§è§„æ¨¡æ•°æ®é›†**: 2,000 ä¸ªè§†é¢‘ï¼Œ14 ç§å¼‚å¸¸ç±»åˆ«
- **å¤šæ¨¡æ€ç‰¹å¾**: æ”¯æŒ RGBã€Flow å’Œç»„åˆ I3D ç‰¹å¾
- **åŒä»»åŠ¡å­¦ä¹ **: åŒæ—¶è¿›è¡Œå¼‚å¸¸åˆ†ç±»å’Œæ—¶é—´å®šä½
- **å…¨é¢åŸºå‡†æµ‹è¯•**: åœ¨ 5 ä¸ªä¸»è¦è§†é¢‘å¼‚å¸¸æ£€æµ‹æ•°æ®é›†ä¸Šçš„è¯„ä¼°
- **å¯å¤ç°å®ç°**: å®Œæ•´çš„è®­ç»ƒå’Œè¯„ä¼°æµç¨‹

## ğŸ“Š æ•°æ®é›†æ¦‚è§ˆ

| ç±»åˆ« | è§†é¢‘æ•°é‡ | æè¿° |
|------|----------|------|
| ç¢°æ’ | 143 | è½¦è¾†ç¢°æ’å’Œäº‹æ•… |
| äººç¾¤èšé›† | 156 | å¼‚å¸¸äººç¾¤èšé›† |
| ç ´å | 142 | è´¢äº§ç ´å |
| å è½ | 145 | ç‰©ä½“ä»é«˜å¤„å è½ |
| æ‘”å€’ | 148 | äººå‘˜æ‘”å€’ |
| è½æ°´ | 139 | è½å…¥æ°´ä½“ |
| æ–—æ®´ | 147 | è‚¢ä½“å†²çª |
| ç«ç¾ | 144 | ç«ç¾äº‹ä»¶ |
| å—ä¼¤ | 146 | èº«ä½“ä¼¤å®³ |
| å¾˜å¾Š | 142 | å¯ç–‘é€—ç•™ |
| ææ…Œ | 143 | ææ…Œæƒ…å†µ |
| å·çªƒ | 145 | ç›—çªƒæ´»åŠ¨ |
| è¸©è¸ | 141 | äººç¾¤è¸©è¸ |
| æš´åŠ› | 129 | æš´åŠ›è¡Œä¸º |

## ğŸ—ï¸ æ¨¡å‹æ¶æ„

æˆ‘ä»¬æå‡ºçš„ **AED (å¼‚å¸¸äº‹ä»¶æ£€æµ‹)** æ¡†æ¶åŒ…å«ï¼š

1. **ConvLSTM ç¼–ç å™¨**: æ•è·æ—¶ç©ºä¾èµ–å…³ç³»
2. **åˆ†ç±»å¤´**: é¢„æµ‹å¼‚å¸¸ç±»åˆ«
3. **å›å½’å¤´**: å®šä½æ—¶é—´ç‰‡æ®µ

### æ¨¡å‹å˜ä½“:
- **AED**: å•å±‚ ConvLSTM
- **AED_T**: åŒå±‚ ConvLSTMï¼Œå¢å¼ºæ—¶é—´å»ºæ¨¡èƒ½åŠ›

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/wanboyang/anomaly_detection_LAD2000.git
cd anomaly_detection_LAD2000

# åˆ›å»ºç¯å¢ƒ
conda env create -f environment.yaml
conda activate anomaly_icme
```

### æ•°æ®å‡†å¤‡

1. ä»[ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1LmNAWnR-RPqo-azCgASvfg)ä¸‹è½½ LAD2000 æ•°æ®é›† (å¯†ç : avt8)
2. æå– I3D ç‰¹å¾æˆ–ä½¿ç”¨é¢„æå–çš„ç‰¹å¾
3. åœ¨é…ç½®ä¸­æ›´æ–°æ•°æ®é›†è·¯å¾„

### è®­ç»ƒ

```bash
# åœ¨ LAD2000 æ•°æ®é›†ä¸Šè®­ç»ƒ
sh LAD2000T_i3d.sh

# åœ¨å…¶ä»–æ•°æ®é›†ä¸Šè®­ç»ƒ
sh ped2_i3d.sh      # UCSD Ped2
sh Avenue_i3d.sh    # Avenue
sh shanghaitech_i3d.sh  # ShanghaiTech
sh UCF_i3d.sh       # UCF-Crime
```

### è¯„ä¼°

```bash
python test.py --dataset_name LAD2000 --model_name AED_T --feature_modal combine
```

## ğŸ“ˆ å®éªŒç»“æœ

| æ•°æ®é›† | AUC | å¸§çº§ AP | è§†é¢‘çº§ AP |
|--------|-----|----------|-----------|
| LAD2000 | 87.2 | 85.6 | 89.1 |
| Avenue | 91.4 | 90.2 | 92.8 |
| Ped2 | 96.8 | 95.3 | 97.5 |
| ShanghaiTech | 84.7 | 82.9 | 86.3 |
| UCF-Crime | 83.5 | 81.2 | 85.1 |

## ğŸ“š å¼•ç”¨

å¦‚æœæ‚¨å‘ç°è¿™é¡¹å·¥ä½œå¯¹æ‚¨çš„ç ”ç©¶æœ‰ç”¨ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@article{wan2021anomaly,
  title={Anomaly detection in video sequences: A benchmark and computational model},
  author={Wan, Boyang and Jiang, Wenhui and Fang, Yuming and Luo, Zhiyuan and Ding, Guanqun},
  journal={IET Image Processing},
  year={2021},
  publisher={Wiley Online Library}
}
```

## ğŸ¤ è‡´è°¢

æˆ‘ä»¬æ„Ÿè°¢ [W-TALC](https://github.com/sujoyp/wtalc-pytorch) çš„è´¡çŒ®è€…å’Œ PyTorch å›¢é˜Ÿæä¾›çš„ä¼˜ç§€æ¡†æ¶ã€‚

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜å’Œå»ºè®®ï¼Œè¯·è”ç³»ï¼š
- **ä¸‡åšæ´‹** - wanboyangjerry@163.com

</div>

<script>
// Language switch functionality
document.addEventListener('DOMContentLoaded', function() {
    const englishBtn = document.querySelector('a[href="#english"]');
    const chineseBtn = document.querySelector('a[href="#chinese"]');
    const englishContent = document.getElementById('english');
    const chineseContent = document.getElementById('chinese');
    
    englishBtn.addEventListener('click', function(e) {
        e.preventDefault();
        englishContent.style.display = 'block';
        chineseContent.style.display = 'none';
        englishBtn.classList.add('active');
        chineseBtn.classList.remove('active');
    });
    
    chineseBtn.addEventListener('click', function(e) {
        e.preventDefault();
        englishContent.style.display = 'none';
        chineseContent.style.display = 'block';
        englishBtn.classList.remove('active');
        chineseBtn.classList.add('active');
    });
    
    // Set English as default
    englishContent.style.display = 'block';
    chineseContent.style.display = 'none';
    englishBtn.classList.add('active');
});

// Add some basic styling for the buttons
const style = document.createElement('style');
style.textContent = `
    .btn {
        display: inline-block;
        padding: 8px 16px;
        margin: 0 5px;
        border: 1px solid #007bff;
        border-radius: 4px;
        text-decoration: none;
        color: #007bff;
        transition: all 0.3s;
    }
    .btn:hover {
        background-color: #007bff;
        color: white;
    }
    .btn.active {
        background-color: #007bff;
        color: white;
    }
    .btn-primary {
        background-color: #007bff;
        color: white;
    }
    .btn-secondary {
        background-color: #6c757d;
        color: white;
        border-color: #6c757d;
    }
`;
document.head.appendChild(style);
</script>
